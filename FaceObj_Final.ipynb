{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import face_recognition\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pickle\n",
        "\n",
        "# ---------------- FACE RECOGNITION SETUP ----------------\n",
        "print(\"[INFO] loading face encodings...\")\n",
        "with open(\"encodings.pickle\", \"rb\") as f:\n",
        "    data = pickle.loads(f.read())\n",
        "known_face_encodings = data[\"encodings\"]\n",
        "known_face_names = data[\"names\"]\n",
        "\n",
        "cv_scaler = 4\n",
        "face_locations = []\n",
        "face_encodings = []\n",
        "face_names = []\n",
        "face_confidences = []\n",
        "\n",
        "# ---------------- YOLO DNN SETUP ----------------\n",
        "print(\"[INFO] loading YOLO model...\")\n",
        "yolo_cfg = \"yolov3.cfg\"\n",
        "yolo_weights = \"yolov3.weights\"\n",
        "yolo_names = \"coco.names\"\n",
        "\n",
        "with open(yolo_names, \"r\") as f:\n",
        "    class_names = [c.strip() for c in f.readlines()]\n",
        "\n",
        "net = cv2.dnn.readNetFromDarknet(yolo_cfg, yolo_weights)\n",
        "net.setPreferableBackend(cv2.dnn.DNN_BACKEND_OPENCV)\n",
        "net.setPreferableTarget(cv2.dnn.DNN_TARGET_CPU)\n",
        "\n",
        "layer_names = net.getLayerNames()\n",
        "out_layers = [layer_names[i - 1] for i in net.getUnconnectedOutLayers()]\n",
        "\n",
        "# ---------------- STATS TRACKING ----------------\n",
        "person_stats = {}  # {name: {\"start\": None, \"end\": None, \"total\": 0.0, \"max_conf\":0.0, \"min_conf\":1.0}}\n",
        "object_stats = {}  # {classname: {\"start\": None, \"end\": None, \"total\": 0.0, \"max_conf\":0.0, \"min_conf\":1.0}}\n",
        "\n",
        "# ---------------- FUNCTIONS ----------------\n",
        "def process_frame(frame, video_time):\n",
        "    global face_locations, face_encodings, face_names, face_confidences\n",
        "\n",
        "    # ---- FACE RECOGNITION ----\n",
        "    resized_frame = cv2.resize(frame, (0, 0), fx=(1/cv_scaler), fy=(1/cv_scaler))\n",
        "    rgb_resized_frame = cv2.cvtColor(resized_frame, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    face_locations = face_recognition.face_locations(rgb_resized_frame)\n",
        "    face_encodings = face_recognition.face_encodings(rgb_resized_frame, face_locations, model='large')\n",
        "\n",
        "    face_names = []\n",
        "    face_confidences = []\n",
        "    for face_encoding in face_encodings:\n",
        "        matches = face_recognition.compare_faces(known_face_encodings, face_encoding)\n",
        "        name = \"Unknown\"\n",
        "        confidence = 0.0\n",
        "\n",
        "        face_distances = face_recognition.face_distance(known_face_encodings, face_encoding)\n",
        "        if len(face_distances) > 0:\n",
        "            best_match_index = np.argmin(face_distances)\n",
        "            if matches[best_match_index]:\n",
        "                name = known_face_names[best_match_index]\n",
        "                confidence = 1 - face_distances[best_match_index]\n",
        "\n",
        "        face_names.append(f\"{name} ({confidence*100:.1f}%)\")\n",
        "        face_confidences.append(confidence)\n",
        "\n",
        "        # Track stats\n",
        "        if name != \"Unknown\":\n",
        "            if name not in person_stats:\n",
        "                person_stats[name] = {\"start\": None, \"end\": None, \"total\": 0.0,\n",
        "                                      \"max_conf\": 0.0, \"min_conf\": 1.0}\n",
        "            if person_stats[name][\"start\"] is None:\n",
        "                person_stats[name][\"start\"] = video_time\n",
        "            person_stats[name][\"end\"] = video_time\n",
        "            person_stats[name][\"total\"] = person_stats[name][\"end\"] - person_stats[name][\"start\"]\n",
        "            # update max/min confidence\n",
        "            if confidence > person_stats[name][\"max_conf\"]:\n",
        "                person_stats[name][\"max_conf\"] = confidence\n",
        "            if confidence < person_stats[name][\"min_conf\"]:\n",
        "                person_stats[name][\"min_conf\"] = confidence\n",
        "\n",
        "    # ---- YOLO OBJECT DETECTION ----\n",
        "    H, W = frame.shape[:2]\n",
        "    blob = cv2.dnn.blobFromImage(frame, 1/255.0, (416, 416), swapRB=True, crop=False)\n",
        "    net.setInput(blob)\n",
        "    detections = net.forward(out_layers)\n",
        "\n",
        "    boxes, confidences, class_ids = [], [], []\n",
        "    for output in detections:\n",
        "        for det in output:\n",
        "            scores = det[5:]\n",
        "            class_id = np.argmax(scores)\n",
        "            conf = scores[class_id]\n",
        "            if conf > 0.5:\n",
        "                center_x = int(det[0] * W)\n",
        "                center_y = int(det[1] * H)\n",
        "                w = int(det[2] * W)\n",
        "                h = int(det[3] * H)\n",
        "                x = int(center_x - w / 2)\n",
        "                y = int(center_y - h / 2)\n",
        "                boxes.append([x, y, w, h])\n",
        "                confidences.append(float(conf))\n",
        "                class_ids.append(class_id)\n",
        "\n",
        "    indices = cv2.dnn.NMSBoxes(boxes, confidences, 0.5, 0.4)\n",
        "    for i in indices.flatten():\n",
        "        x, y, w, h = boxes[i]\n",
        "        classname = class_names[class_ids[i]]\n",
        "        conf = confidences[i]\n",
        "        label = f\"{classname}: {int(conf*100)}%\"\n",
        "        cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
        "        cv2.putText(frame, label, (x, y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0,0,0), 2)\n",
        "\n",
        "        # Track stats\n",
        "        if classname not in object_stats:\n",
        "            object_stats[classname] = {\"start\": None, \"end\": None, \"total\": 0.0,\n",
        "                                       \"max_conf\": 0.0, \"min_conf\": 1.0}\n",
        "        if object_stats[classname][\"start\"] is None:\n",
        "            object_stats[classname][\"start\"] = video_time\n",
        "        object_stats[classname][\"end\"] = video_time\n",
        "        object_stats[classname][\"total\"] = object_stats[classname][\"end\"] - object_stats[classname][\"start\"]\n",
        "        if conf > object_stats[classname][\"max_conf\"]:\n",
        "            object_stats[classname][\"max_conf\"] = conf\n",
        "        if conf < object_stats[classname][\"min_conf\"]:\n",
        "            object_stats[classname][\"min_conf\"] = conf\n",
        "\n",
        "    return frame\n",
        "\n",
        "def draw_results(frame):\n",
        "    # Draw faces\n",
        "    for (top, right, bottom, left), name_with_confidence in zip(face_locations, face_names):\n",
        "        top *= cv_scaler\n",
        "        right *= cv_scaler\n",
        "        bottom *= cv_scaler\n",
        "        left *= cv_scaler\n",
        "        cv2.rectangle(frame, (left, top), (right, bottom), (0, 255, 255), 2)\n",
        "        cv2.rectangle(frame, (left-3, top-35), (right+3, top), (0, 255, 255), cv2.FILLED)\n",
        "        cv2.putText(frame, name_with_confidence, (left+6, top-6),\n",
        "                    cv2.FONT_HERSHEY_DUPLEX, 1.0, (0,0,0), 2)\n",
        "\n",
        "    # Overlay person stats\n",
        "    y_offset = 70\n",
        "    for name, stats in person_stats.items():\n",
        "        cv2.putText(frame,\n",
        "                    f\"{name}: {stats['total']:.1f}s | Max {stats['max_conf']*100:.1f}% | Min {stats['min_conf']*100:.1f}%\",\n",
        "                    (10, y_offset), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255,255,0), 2)\n",
        "        y_offset += 25\n",
        "\n",
        "    # Overlay object stats\n",
        "    for obj, stats in object_stats.items():\n",
        "        cv2.putText(frame,\n",
        "                    f\"{obj}: {stats['total']:.1f}s | Max {stats['max_conf']*100:.1f}% | Min {stats['min_conf']*100:.1f}%\",\n",
        "                    (10, y_offset), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0,255,255), 2)\n",
        "        y_offset += 25\n",
        "\n",
        "    return frame\n",
        "\n",
        "# ---------------- MAIN LOOP ----------------\n",
        "video = cv2.VideoCapture(\"nav_backlight.mp4\")\n",
        "fps = video.get(cv2.CAP_PROP_FPS)\n",
        "\n",
        "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "out = cv2.VideoWriter(\"output_backlight.mp4\", fourcc, fps,\n",
        "                      (int(video.get(cv2.CAP_PROP_FRAME_WIDTH)),\n",
        "                       int(video.get(cv2.CAP_PROP_FRAME_HEIGHT))))\n",
        "\n",
        "while True:\n",
        "    ret, frame = video.read()\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "    frame_number = int(video.get(cv2.CAP_PROP_POS_FRAMES))\n",
        "    video_time = frame_number / fps  # seconds into video timeline\n",
        "\n",
        "    processed_frame = process_frame(frame, video_time)\n",
        "    display_frame = draw_results(processed_frame)\n",
        "\n",
        "    out.write(display_frame)\n",
        "    cv2.imshow('Face + YOLO DNN Detection', display_frame)\n",
        "\n",
        "    if cv2.waitKey(1) == ord(\"q\"):\n",
        "        break\n",
        "\n",
        "video.release()\n",
        "out.release()\n",
        "cv2.destroyAllWindows()\n"
      ],
      "metadata": {
        "id": "Tx70S6ociXl7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}